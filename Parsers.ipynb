{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XslJSFkAe5-5",
        "XFUPJo-qsusT"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KuzyaLakomkin1/DataAnalyst/blob/main/Parsers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ссылка на облако с файлами\n",
        "https://cloud.mail.ru/public/Hghv/copkPE88B"
      ],
      "metadata": {
        "id": "eiO-Kq813P_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Задание 1. Библиотека VK API"
      ],
      "metadata": {
        "id": "XslJSFkAe5-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Напишите код, который получает список названия школ города Кемерово с помощью библиотеки vk_api и записывает результаты в файл JSON."
      ],
      "metadata": {
        "id": "Fv1R9qMftlt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PyCharm Community Edition 2022.2.4\n",
        "import vk_api\n",
        "import json\n",
        "from pprint import pprint\n",
        "\n",
        "ACCES_TOKEN = \"vk1.a.QancsiPLels4wNydZGMpvkA0vASrIxi8Uv_acFDH5ZfQmyf7oYKGWL7FUwyQLEqRD9p1HCN5G6EiwXrkmq0XFTRI90GF2b5SUHn23cfkLBdkwIus8bOEIaKv_FkKBRofJzP7MibtJImzFvfYBnrJZfVyX_72aO284yzTYdxr37Jt0J_u1wbtWZyaYDTcNsGD6tbB89Dn_lCbbgcg_kVuAQ\"\n",
        "vk_session = vk_api.VkApi(token=ACCES_TOKEN)\n",
        "vk = vk_session.get_api()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    try:\n",
        "        country_id = vk.database.getCities(country_id=1, q=\"Кемерово\", count=1)['items'][0]['id']\n",
        "        schools_info = vk.database.getSchools(access_token=ACCES_TOKEN, city_id=64)\n",
        "        result_list = []\n",
        "        items = schools_info[\"items\"]\n",
        "        for item in items:\n",
        "            result_list.append({\n",
        "                \"title\": item['title']})\n",
        "        with open(\"task.json\", \"w\") as f:\n",
        "            result = {\"result\": result_list}\n",
        "            json.dump(result, f, ensure_ascii=False)\n",
        "            pprint(result)\n",
        "\n",
        "\n",
        "    except Exception as ex:\n",
        "        print(f\"ERROR: {ex}\")\n"
      ],
      "metadata": {
        "id": "rufJxiJufcPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Когда сдаёте  задания по VK API, можете не переживать за сохранность токена (кроме тьюторов никто решение не увидит). Однако при желании можете удалить свой токен (тьюторы в любом случае проверят сданное задание)."
      ],
      "metadata": {
        "id": "SSvHDb2m1nsY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Возможный алгоритм решения задачи:"
      ],
      "metadata": {
        "id": "v4_ZEnTShH_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Получаем токен доступа к API Вконтакте\n",
        "2.   Инициализируем сессию библиотеки VK_API с помощью токена доступа\n",
        "3. Получаем доступ с помощью VK_API к API «ВКонтакте» методом get_api\n",
        "4. Следуя методу из документации для получения городов и используя библиотеку VK_API, составляем запрос на получение информации о городе «Кемерово» и получаем его id из ответа на запрос\n",
        "5. Следуя методу из документации для получения школ и используя библиотеку VK_API, составляем запрос на получение информации о школах города «Кемерово» (по найденному id) и получаем список названия школ\n",
        "10. Конкретный формат не указан, поэтому создаем JSON с удобными ключами.<br>Например: result: {schools: [...]}\n",
        "11. Записываем созданный  словарик  в файл с форматом JSON\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oYJIXxVOBmHk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Задание 2. Запись данных в CSV формат"
      ],
      "metadata": {
        "id": "N1UzGf1CtVfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "С помощью методов API «ВКонтакте» получите 1000 подписчиков группы «Лентач», отсортирванных по дате регистрации ВКонтакте (не дата вступления в сообщество).\n",
        "\n",
        "Вам необходимо собрать следующие данные в CSV файл: пол, название город, семейное положение (ФИО партнера не указывать)."
      ],
      "metadata": {
        "id": "Rg-gNSTzfA7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PyCharm Community Edition 2022.2.4\n",
        "import vk_api\n",
        "import csv\n",
        "\n",
        "ACCES_TOKEN = \"\"\n",
        "vk_session = vk_api.VkApi(token=ACCES_TOKEN)\n",
        "vk = vk_session.get_api()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        group_id = vk.groups.search(token=ACCES_TOKEN, q=\"Лентач\")[\"items\"][0][\"id\"]\n",
        "        group_members = vk.groups.getMembers(token=ACCES_TOKEN, group_id=29534144, fields=['sex', 'city', 'personal'])\n",
        "        print(group_id)\n",
        "\n",
        "        with open('lentach_members.csv','w', encoding='utf-8') as file:\n",
        "          writer = csv.writer(file)\n",
        "          writer.writerow(['ID', 'First Name', 'Last Name', 'Sex', 'City'])\n",
        "          for member in group_members['items']:\n",
        "            writer.writerow([member['id'], member['first_name'], member['last_name'], member['sex'],\n",
        "                             member['city']['title'] if 'city' in member else \"\"])\n",
        "    except Exception as ex:\n",
        "        print(f\"ERROR{ex}\")\n"
      ],
      "metadata": {
        "id": "eSslPXrGfDRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Когда сдаёте  задания по VK API, можете не переживать за сохранность токена (кроме тьюторов никто решение не увидит). Однако при желании можете удалить свой токен (тьюторы в любом случае проверят сданное задание)."
      ],
      "metadata": {
        "id": "ieTzyyTt4JKw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Возможный алгоритм решения задачи:"
      ],
      "metadata": {
        "id": "6rKWxkGBhRvH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Получаем токен доступа к API Вконтакте\n",
        "2. Инициализируем сессию библиотеки VK_API с помощью токена доступа\n",
        "3. Получаем доступ с помощью VK_API к API вконтакте методом get_api\n",
        "4. Следуя методу из документации для получения сообществ и используя библиотеку VK_API, составляем запрос на получение информации о сообществе «Лентач» и получаем его id из ответа на запрос\n",
        "5. Следуя методу (getMembers) из документации для получения участников сообщества и используя библиотеку VK_API, составляем запрос на получение информации о участниках сообщества «Лентач» (по найденному id) и получаем пол, город и СП каждого из участников\n",
        "6. С помощью CSV библиотеки записываем полученные данные в файл с форматом csv\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yHNVe0qbDCbP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Задание 3. Скрещиваем Selenium и BeautifulSoup"
      ],
      "metadata": {
        "id": "XFUPJo-qsusT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Соберите информацию с сайта nbcomputers.ru (https://www.nbcomputers.ru/catalog/noutbuki/) о ноутбуках данного интернет-магазина.\n",
        "<br>\n",
        "Данные, которые необходимы:\n",
        "* Название ноутбука\n",
        "* Цена ноутбука\n",
        "* Код товара\n",
        "\n",
        "Результат необходимо записать в CSV файл.\n",
        "<br>\n",
        "*(совет: обязательно делайте различные временные промежутки между прокликами)*"
      ],
      "metadata": {
        "id": "9O8NOJs51u8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PyCharm Community Edition 2022.2.4\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service as ChromeService\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from selenium.webdriver.support.wait import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "\n",
        "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
        "\n",
        "try:\n",
        "    driver.get('https://www.nbcomputers.ru/catalog/noutbuki/')\n",
        "    driver.implicitly_wait(10)\n",
        "    actions = ActionChains(driver)\n",
        "    wait = WebDriverWait(driver, timeout=5)\n",
        "    btn_show_more = driver.find_element(By.CSS_SELECTOR, \"button.sc-47746e2f-0.ksEKWt\")\n",
        "    actions.move_to_element(btn_show_more)\n",
        "    actions.perform()\n",
        "    while True:\n",
        "        wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button.sc-47746e2f-0.ksEKWt'))).click()\n",
        "\n",
        "\n",
        "\n",
        "except Exception as ex:\n",
        "    print(f'Error: {ex}')\n",
        "\n",
        "html = driver.page_source\n",
        "print(html)\n",
        "driver.quit()"
      ],
      "metadata": {
        "id": "ORwgF2mYffFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PyCharm Community Edition 2022.2.4\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from time import sleep\n",
        "import lxml\n",
        "import csv\n",
        "\n",
        "URL = \"https://www.nbcomputers.ru/catalog/noutbuki/\"\n",
        "\n",
        "session = requests.session()\n",
        "headers = {\n",
        "    \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
        "                  \"(KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36\",\n",
        "    \"Accept-Language\": \"ru,en;q=0.9,en-US;q=0.8,ru-RU;q=0.7\"\n",
        "}\n",
        "response = session.get(URL, headers=headers)\n",
        "html = response.text\n",
        "\n",
        "soup = BeautifulSoup(html, \"lxml\")\n",
        "\n",
        "all = soup.find_all('article', class_='sc-ba83ea5a-0 dXYWyV')\n",
        "\n",
        "with open('nbcomputers.csv', 'w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Name', 'Code', 'Price'])\n",
        "    for data in all:\n",
        "        name = data.find('div', class_='sc-ba83ea5a-15 bXzchn').text.strip()\n",
        "        code = data.find('div', class_='sc-ba83ea5a-10 gdFLFg').find('p').text.strip()\n",
        "        price = data.find('span', class_='sc-96470d6e-2 gaNDhP').text.strip()\n",
        "        writer.writerow([name, code, price])\n"
      ],
      "metadata": {
        "id": "3V6Q_SzKrcc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Данный скрипт собирает только 31 товар(Т.е с первой страницы).Не могу понять почему,скрипт нажимает кнопку показать ещё.Прошу помочь разобраться и внести корректировки .\n",
        "\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from bs4 import BeautifulSoup\n",
        "import lxml\n",
        "import csv\n",
        "\n",
        "\n",
        "driver = webdriver.Chrome()\n",
        "\n",
        "driver.get('https://www.nbcomputers.ru/catalog/noutbuki/')\n",
        "driver.implicitly_wait(10)\n",
        "wait = WebDriverWait(driver, 5)\n",
        "\n",
        "a = 1\n",
        "while a < 25:\n",
        "    try:\n",
        "        button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.sc-47746e2f-0.ksEKWt\"))).click()\n",
        "        a += 1\n",
        "\n",
        "    except Exception as ex:\n",
        "        print(f'Error: {ex}')\n",
        "\n",
        "html = driver.page_source\n",
        "soup = BeautifulSoup(html, 'lxml')\n",
        "all = soup.find_all('article', class_='sc-ba83ea5a-0 dXYWyV')\n",
        "\n",
        "with open('nbcomputers.csv', 'w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Name', 'Code', 'Price'])\n",
        "    for data in all:\n",
        "        name = data.find('div', class_='sc-ba83ea5a-15 bXzchn').text.strip()\n",
        "        code = data.find('div', class_='sc-ba83ea5a-10 gdFLFg').find('p').text.strip()\n",
        "        price = data.find('span', class_='sc-96470d6e-2 gaNDhP').text.strip()\n",
        "        writer.writerow([name, code, price])\n",
        "\n"
      ],
      "metadata": {
        "id": "4lvryU5uB87n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Возможный алгоритм решения задачи в Colab (простой):"
      ],
      "metadata": {
        "id": "wLgQzytJh7V_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Возможный алгоритм решения задачи в коллабе (простой):\n",
        "1. Установливаем параметры для headless браузера\n",
        "2. Инициализацируем сессию браузера\n",
        "3. Переходим по данной ссылке\n",
        "4. Устанавливаем неявное ожидание\n",
        "5. Инициализируем явное ожидание для нажатия на кнопку \"Больше\"\n",
        "6. С помощью бесконечного цикла жмем на кнопку методом click, пока она кликабельна  (ну и не забываем про селектор)\n",
        "4. Оборачиваем все в trt except.Когда вылетит с ошибкой того, что кнопка не кликабельна => прогрузили все карточки\n",
        "\n",
        "5. С помощью BS находим блок карточек\n",
        "6. Поочереднно собираем необходимые данные с карточки\n",
        "7. Записываем все в файл с форматом csv, используя CSV библиотеку\n",
        "\n"
      ],
      "metadata": {
        "id": "TfOWoc4glonj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Задание 4. Фреймворк Scrapy"
      ],
      "metadata": {
        "id": "2kKiYGTFfSpV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Соберите информацию о заквасках с сайта pro-syr.ru (https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
        "\n",
        "Необходимо собрать следующие данные:\n",
        "* Название продукта\n",
        "* Цена\n",
        "* Есть ли продукт в наличии\n",
        "\n",
        "Результат должен быть записан в CSV файл"
      ],
      "metadata": {
        "id": "A6UOPxtk563f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scrapy\n",
        "import time\n",
        "\n",
        "class leavenSpider(scrapy.Spider):\n",
        "  name = 'leavenSpider'\n",
        "  start_urls = ['https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/']\n",
        "\n",
        "  def parse(self, response):\n",
        "    links = response.css('div.nameproduct a::attr(href)')\n",
        "    for link in links:\n",
        "      time.sleep(1)\n",
        "      yield response.follow(link, self.parse_cheese)\n",
        "\n",
        "    link = response.css('ul.pagination a::attr(href)').get()\n",
        "    yield response.follow(link, self.parse)\n",
        "\n",
        "  def leavenSpider(self, response):\n",
        "    yield {\n",
        "        'name': response.css('div.col-md-9 h1::text').get(),\n",
        "        'price': response.css('li.price span::text').get(),\n",
        "        'stock': response.css('div.product-description b::text').get()\n",
        "    }\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0zUq-Xwlfgjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scrapy crawl \"leavenSpider\" -o \"leaven.csv\""
      ],
      "metadata": {
        "id": "u5cHPcPuze16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Возможный алгоритм решения задачи:"
      ],
      "metadata": {
        "id": "Bp_AOQKphZDX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Инициализируем проект SCRAPY\n",
        "2. В папке spiders создаем своего паука\n",
        "3. Создаем класс с пауком и наследуемся от scrapy.Spider\n",
        "4. Называем паука так же, как и класс\n",
        "5. Указываем стартовую ссылку\n",
        "6. Создаем функцию парсинга карточки, где описываем получение данных из карточки в словарь (название, цена и запас). Возвращаем обратно словарь через yield.\n",
        "7. Создаем функцию parse — основую логику перехода по ссылкам\n",
        "8. Получаем ссылки на каждую карточек текущей страницы\n",
        "9. Циклом проходимся по каждой и собираем данные через ранне коллбек функцию\n",
        "10. Дальше в функции parse расписываем переход на следующую страницу. Для этого находим в пагинации ссылку на следующую страницу  и переходим на нее до тех пор, пока она не закончится.\n",
        "11. В командной строке переходим в папку с проектом scrapy (%cd <название проекта>/)\n",
        "12. В командной строке пишем команду !scrapy runspider <название паука или путь до него из папки с проектом> -o <Название файла с форматом csv, куда будет записан результат парсинга>\n",
        "\n",
        "\n",
        "Не забывайте пользоваться scrapy shell!"
      ],
      "metadata": {
        "id": "s2id-iqTmngO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ynmLASz753Ll"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}